{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "#This is really crazy how fancy these packages seem for concepts such as paths and files\n",
    "\n",
    "#PATHLIB is something that has a class for good path operations (works across OS, that's probably why its op)\n",
    "#SHUTIL I understand the least. Looks like it's responsible for deleting things? Again a simple command\n",
    "#TEMPFILE is a package for making temporary files and directories, so you can save space when done with an operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gz = tf.keras.utils.get_file('HIGGS.csv.gz', 'http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz')\n",
    "#This was over 2 gigs and somehow downloaded in 1 min? What happened? Is it the way the file is stored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we read the data inside the ZIP without even having to open it!\n",
    "#The data gets stored into a complicated object of the CSVDataset class, we call it ds\n",
    "#There are many methods and complexities to this object.\n",
    "\n",
    "#I had to use for loops to inspect the object but it looks like a collection of tuples\n",
    "#Each tuple contains a list of Tensors (vectors?) \n",
    "\n",
    "#But the tensor object can have not just numbers within but attributes and methods.\n",
    "#I noticed the shape and data type attributes\n",
    "#There is a shape method which returns the shape attribute. \n",
    "#OOO a device attribute shows which node its located on when calculating (I think)\n",
    "\n",
    "\n",
    "FEATURES = 28\n",
    "ds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can then map a function to each tuple. \n",
    "#We will strip the first Tensor as the labels, then stack the remainder as the data.\n",
    "#I think stack is the idea of taking a grid and squishing it along an acis (yet not summing?)\n",
    "#It honestly just feels like a transpose in this case, maybe with a 3D tensor or higher it would make sense...\n",
    "\n",
    "def pack_row(*row):\n",
    "    label = row[0]\n",
    "    features = tf.stack(row[1:],1)\n",
    "    return features, label\n",
    "\n",
    "#Here is a neat python syntax note: setting a function variable like *row allows for the argument to be of variable length\n",
    "#Wait what? Isn't that the same as a list? Just look at the way row is used within the function, it's just a list!\n",
    "#Hold on, it allows for the call of the function to look like: pack_row(a,b,c). \n",
    "#Which is somehow different than calling it like: pack_row([a,b,c])? Ugh anyway. I've seen this a BUNCH with\n",
    "#*args, **kwars and so on. So it's nice to kind of study it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Honestly I'm guessing I know how to do all this stuff if I were to be working with my own data etc...\n",
    "#It's just that this is higher level with more features of the objects to take advantage of.\n",
    "#But at the end of the day, I can sloppily manipulate my data into any necessary format\n",
    "\n",
    "packed_ds = ds.batch(10000).map(pack_row).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
